/*
========================================================================================
    Nextflow config file for Rosalind HPC at CDC
==========================================================================================
    This is a configuration file to run Nextflow pipeline on CDC's Sun Grid Engine, and is 
    configured to optimally schedule jobs to various queues and handles resource limits, 
    ensuring that nothing breaks in the cluster. This config also sets necessary parameters 
    for Conda and Singularity, and disables Docker. Note that temporary and cache directories 
    are defined below, and you should change them if necessary. This config file should be 
    passed to the Nextflow run command using -C, which will overwrite default configs.
----------------------------------------------------------------------------------------
*/

/*
========================================================================================
    Load base.config and nextflow.config by default for all pipelines (if it exists). Any 
    overlapping settings will be overwritten by proceeding code.
========================================================================================
*/

/*
========================================================================================
    Default institutional and max resource paramters - subject to overwrite.
========================================================================================
*/

params {
  config_profile_description = 'Rosalind HPC @ CDC'
  config_profile_contact = 'OAMD'
  config_profile_url = 'https://info.biotech.cdc.gov/info/'
  custom_config_version = 'master'
  tracedir = "${params.outdir}/pipeline_info"
  max_memory                 = '128.GB'
  max_cpus                   = 16
  max_time                   = '240.h'
  schema_ignore_params = 'genomes'
}

/*
========================================================================================
    Base Executor config
========================================================================================
*/

executor {
  queueSize = 24
  submitRateLimit = '2sec'
  pollInterval = '5 sec'
}

/*
========================================================================================
    Default local execution parameters and environment variables.
========================================================================================
*/

process {
  executor = 'local'
  // Default resources
  cpus = '4'
  memory = '12.GB'
  time = '4.h'
}

env {
  TMPDIR = "$HOME/tmp"
  NXF_DEBUG = '3'
  // NXF_WORK = 
}

/*
========================================================================================
    Container configurations.
========================================================================================
*/

conda {
  enabled = false
  cacheDir = "$HOME/my_conda_envs/cache"
  useMamba = false
  docker.enabled = false
}

// Singularity configuration
singularity {
  enabled = true
  autoMounts = true
  cacheDir = "$HOME/singularityIMG"
  docker.enabled = false
}

/*
========================================================================================
    CDC Rosalind sge profile
========================================================================================
*/

profiles {
  rosalind {
    process {
      // Executor information
      executor = 'sge'
      penv = 'smp'
      // : task.memory >= 72.GB ? 'highmem.q' doesn't work, highmem.q just hangs
      queue = { task.time <= 4.h ? 'short.q' : task.time > 24.h ? 'long.q' : 'all.q' }

      // Default resources
      cpus = '2'
      memory = '12.GB'
      time = '4.h'

      // Set h_vmem option for qsub submissions
      clusterOptions = { "-l h_vmem=${task.memory.toString().replaceAll(/[\sB]/,'')}" }

      // Error handling - increases resources on each retry.
      errorStrategy = { task.exitStatus in [143,137,104,134,139,140,71,255] ? 'retry' : 'finish' }
      maxRetries    = 3
      maxErrors     = '-1'

      withLabel:process_single {
          cpus   = { check_max( 1                  , 'cpus'    ) }
          memory = { check_max( 6.GB * task.attempt, 'memory'  ) }
          time   = { check_max( 4.h  * task.attempt, 'time'    ) }
      }
      withLabel:process_low {
          cpus   = { check_max( 2     * task.attempt, 'cpus'    ) }
          memory = { check_max( 12.GB * task.attempt, 'memory'  ) }
          time   = { check_max( 4.h   * task.attempt, 'time'    ) }
      }
      withLabel:process_medium {
          cpus   = { check_max( 6     * task.attempt, 'cpus'    ) }
          memory = { check_max( 36.GB * task.attempt, 'memory'  ) }
          time   = { check_max( 8.h   * task.attempt, 'time'    ) }
      }
      withLabel:process_high {
          cpus   = { check_max( 12    * task.attempt, 'cpus'    ) }
          memory = { check_max( 72.GB * task.attempt, 'memory'  ) }
          time   = { check_max( 16.h  * task.attempt, 'time'    ) }
      }
      withLabel:process_long {
          time   = { check_max( 20.h  * task.attempt, 'time'    ) }
      }
      withLabel:process_high_memory {
          memory = { check_max( 200.GB * task.attempt, 'memory' ) }
      }
      withLabel:error_ignore {
          errorStrategy = 'ignore'
      }
      withLabel:error_retry {
          errorStrategy = 'retry'
          maxRetries    = 5
      }
      withName:CUSTOM_DUMPSOFTWAREVERSIONS {
          cache = false
      }
    } 
  
    executor {
      queueSize = 24
      submitRateLimit = '2sec'
      pollInterval = '5 sec'
    }
  }
}

/*
========================================================================================
    Capture exit codes from upstream processes when piping
========================================================================================
*/

process.shell = ['/bin/bash', '-euo', 'pipefail']

/*
========================================================================================
    Nextflow Metrics & Reports
========================================================================================
*/
def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')

timeline {
    enabled = true
    file    = "${params.tracedir}/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.tracedir}/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.tracedir}/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = true
    file    = "${params.tracedir}/pipeline_dag_${trace_timestamp}.html"
}

/*
========================================================================================
    Function to check max resources
========================================================================================
*/

def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}

